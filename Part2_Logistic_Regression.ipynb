{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "\n",
    "In the assignment, you will use gradient ascent to find the weights for the logistic regression.   \n",
    "\n",
    "As an example, we will use the widely-used breast cancer data set.  This data set is described here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, preprocessing, and understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "# Import breastcancer dataset\n",
    "# Import preprocessing from sklearn\n",
    "# Import train_test_split from sklearn\n",
    "# Import numpy,math\n",
    "\n",
    "import sklearn\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset to a python variable cancer\n",
    "# Store target to a variable called y\n",
    "# Store feature to a variable called X\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "x = breast_cancer.data\n",
    "y = breast_cancer.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of data (X) and target (Y) values \n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "#### Splitting the data into train and test before scaling the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split() function to split the dataset\n",
    "# Store the return value of pervious step to X_train, X_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the scaler of the dataset by using preprocessing.StandardScaler().fit()\n",
    "# Using this scale to scale the X_train and X_test using .transform()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of x_train and y_train \n",
    "\n",
    "print(x_train.shape) # It should print (426, 30)\n",
    "print(y_train.shape) # It should print (426,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a column of ones to the  matrices $X_{train}$ and  $X_{test}$\n",
    "After adding a column of ones $X_{train}=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "\n",
    "Similarly for $X_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old test data dimensions: (143, 32)\n",
      "The trainng data has dimensions:  (426, 33) . The testing data has dimensions:  (143, 33)\n",
      "[[ 1.          1.          1.         -0.64962332 -0.08136555 -0.67795088\n",
      "  -0.64529589 -0.54443564 -0.66976393 -0.77978067 -0.90250941 -1.01722084\n",
      "  -0.31578688 -0.66038458 -0.63802025 -0.70396285 -0.51081543 -0.50801357\n",
      "  -0.4587491  -0.37943957 -0.81901884 -0.53060218 -0.33017706 -0.61486734\n",
      "  -0.11191003 -0.656516   -0.58764056 -0.19150121 -0.42153826 -0.60011494\n",
      "  -0.69244814 -0.5917125  -0.22253979]\n",
      " [ 1.          1.          1.          0.60855956  0.33052533  0.6150095\n",
      "   0.45167449  1.46171817  0.52228412  0.74075188  0.92757364  0.49792067\n",
      "  -0.00391398  0.11667834  0.02748109  0.19996305  0.08961122 -0.11466429\n",
      "  -0.25978234  0.01943942  0.34451109 -0.62746498 -0.38048449  0.62348619\n",
      "   0.765818    0.67133668  0.42263187  1.16741142  0.25722281  0.41983856\n",
      "   0.66530755  0.32718689 -0.10782905]]\n"
     ]
    }
   ],
   "source": [
    "# Append a column of ones to x_train \n",
    "\n",
    "row_ones = np.ones(len(x_train))\n",
    "\n",
    "# Create a column vector of ones by using np.ones and reshape\n",
    "# Append a column of ones in the beginning of x_train by using np.hstack\n",
    "\n",
    "col_ones = row_ones.reshape(-1,1)\n",
    "#print(col_ones.shape)\n",
    "x_train = np.hstack((col_ones, x_train))\n",
    "\n",
    "# Now do the same for the test data\n",
    "print(\"Old test data dimensions:\", x_test.shape)\n",
    "row_ones = np.ones(len(x_test))\n",
    "col_ones = row_ones.reshape(-1,1)\n",
    "#print(x_test.shape)\n",
    "#print(col_ones.shape)\n",
    "x_test = np.hstack((col_ones, x_test))\n",
    "\n",
    "# We can check that everything worked correctly by:\n",
    "# Printing out the new dimensions\n",
    "print(\"The trainng data has dimensions: \", x_train.shape, \". The testing data has dimensions: \",x_test.shape)\n",
    "\n",
    "# # Looking at the first two rows of X_train to check everything worked as expected\n",
    "print(x_train[0:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Printing the names of all the features\n",
    "# print(cancer.feature_names)\n",
    "\n",
    "print(breast_cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add your own code here to better understand the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Before writing the gradient ascent code, first write some helpful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "### Sigmoid($z$)\n",
    "The first function you will write is sigmoid($z$)\n",
    "\n",
    "sigmoid($z$) takes as input a column vector of real numbers, $z^T = [z_1, z_2, ..., z_{N'}]$, where $N'$ is the number of  examples\n",
    "\n",
    "It should produce as output a column vector $\\left[\\frac{1}{1+e^{-z_1}},\\frac{1}{1+e^{-z_2}},...,\\frac{1}{1+e^{-z_{N'}}}\\right]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the sigmoid function\n",
    "def sigmoid(z):\n",
    "    \n",
    "    y = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing ${\\bf w}$\n",
    "For testing the next functions, we create a coefficient vector, ${\\bf w}$.\n",
    "We will initialize the coeffients to be $0$, i.e. ${\\bf w}^T = [0,0,\\ldots ,0]$ (We could have initialized ${\\bf w}$ to any values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w using np.zeros()\n",
    "\n",
    "w = np.zeros((x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our hypothesis, $h({\\bf x})$\n",
    "The next  function to write is our hypothesis function. \n",
    "\n",
    "For example if our design matrix $X$ consists of single example $X=[1,x_1,x_2,\\ldots,x_d]$ and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, it returns $h({\\bf x})=\\frac{1}{1+e^{-\\left({w_{0}\\cdot 1 +w_1\\cdot x_1+\\cdots w_d\\cdot x_d}\\right)}}$\n",
    "\n",
    "If given a  matrix consisting of $N'$ examples \n",
    "$X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, the function returns a column vector\n",
    "$[h({\\bf x}^{(1)}),h({\\bf x}^{(2)},\\ldots, h({\\bf x}^{(N')}]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probability that a patient has cancer \n",
    "# Write the hypothesis function \n",
    "def hypothesis(x , w):\n",
    "    \n",
    "    h = sigmoid(np.dot(x, w))\n",
    "\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood Function.\n",
    "Write the code to calculate the log likelihood function $\\ell({\\bf w})=\n",
    "\\sum_{i=1}^{N'}y^{(i)}\\ln(h({\\bf x}^{(i)})) +(1- y^{(i)})\\ln(1-h({\\bf x}^{(i)}))$\n",
    "\n",
    "The input is a matrix consisting of $N'$ examples $X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and a column vector ${\\bf y}^T=[y^{(1)},y^{(2)},\\dots,y^{(N')}]$ of labels for $X$.\n",
    "\n",
    "The output is $\\ell({\\bf w})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the log likelihood function \n",
    "def log_likelihood(x , y , w ):\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    h = hypothesis(x, w)\n",
    "    log_like = (1/m)*np.sum(y*np.log(h)+(1-y)*np.log(1-h))\n",
    "\n",
    "    return log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent\n",
    "Now write the code to perform gradient ascent.  You will use the update rule from the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the gradient ascent function \n",
    "def Logistic_Regresion_Gradient_Ascent(x, y, learning_rate, num_iters):\n",
    "    # For every 100 iterations, store the log_likelihood for the current w\n",
    "    # Initializing log_likelihood to be an empty list  \n",
    "    # Initialize w to be a zero vector of shape x_train.shape[1],1\n",
    "    # Initialize N to the number of training examples\n",
    "    \n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    log_likelihood_values = []\n",
    "    w = np.zeros((x.shape[1],1))\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # update the w using formula \n",
    "        # append the log_likelihodd values to the list for every 100 iterations\n",
    "        h = hypothesis(x, w)\n",
    "        gradient = (1/N)*np.dot(x.T, h-y)\n",
    "        w = w - learning_rate*gradient\n",
    "        \n",
    "        if(i%100==0):\n",
    "            log_likelihood_values.append(log_likelihood(x,y,w))\n",
    "        \n",
    "    return w, log_likelihood_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After completing the code above, run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [[-0.70635986]\n",
      " [ 0.42049997]\n",
      " [-0.45758485]\n",
      " [ 0.42953387]\n",
      " [-0.1147358 ]\n",
      " [-0.85557905]\n",
      " [ 2.34375681]\n",
      " [-1.21676924]\n",
      " [-1.78480458]\n",
      " [ 1.14724635]\n",
      " [ 0.11068737]\n",
      " [-3.32171659]\n",
      " [ 0.60463241]\n",
      " [-1.04854896]\n",
      " [-2.71069445]\n",
      " [-0.10536849]\n",
      " [ 0.95061307]\n",
      " [-0.50187958]\n",
      " [-1.52144379]\n",
      " [ 0.31475993]\n",
      " [ 2.56653339]\n",
      " [-2.06086893]\n",
      " [-2.37579937]\n",
      " [-1.32645571]\n",
      " [-2.26246946]\n",
      " [-0.37392621]\n",
      " [ 0.58843677]\n",
      " [-1.38616775]\n",
      " [-1.44431416]\n",
      " [-1.71084831]\n",
      " [-2.33700623]]\n",
      "llv [-0.23278924318017932, -0.07654771856785955, -0.06862802190321325, -0.06498706775275842, -0.06270074059127333, -0.06102618107787568, -0.059692844244571094, -0.0585791951286636, -0.057621836206039966, -0.05678327415101872, -0.05603853669654927, -0.05536931311028145, -0.05476157243444625, -0.05420456803166357, -0.05369014966548121, -0.05321211305620709, -0.0527656467596465, -0.05234692542206676, -0.05195283362105122, -0.05158078217567378, -0.051228584079390634, -0.050894368084251955, -0.05057651644508788, -0.050273618654592934, -0.049984436130282285, -0.049707874647757035, -0.04944296241250966, -0.049188832340255964, -0.04894470754756449, -0.04870988933783844, -0.048483747158636466, -0.04826571013822706, -0.04805525990251472, -0.04785192444080334, -0.04765527283843414, -0.04746491073149548, -0.04728047636710758, -0.04710163717466237, -0.046928086770522785, -0.04675954233224399, -0.046595742289218006, -0.04643644428538796, -0.04628142337678569, -0.04613047043246441, -0.045983390712190333, -0.04584000259822464, -0.04570013646183288, -0.04556363364792011, -0.045430345563512414, -0.0453001328577627]\n"
     ]
    }
   ],
   "source": [
    "# Set the learning_rate\n",
    "learning_rate = 0.5\n",
    "# Set the num_iters\n",
    "num_iters = 5000\n",
    "# Run the Logistic_Regresion_Gradient_Ascent() and store the returned values\n",
    "w, log_likelihood_values = Logistic_Regresion_Gradient_Ascent(x_train, y_train, learning_rate, num_iters)\n",
    "print(\"w\", w)\n",
    "print(\"llv\", log_likelihood_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,log_likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluating your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hypothesis(...) to predict.\n",
    "\n",
    "y_predict = hypothesis(x_test,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9895833333333334\n",
      "Recall:  0.979381443298969\n",
      "F1:  0.9844559585492227\n",
      "Confusion Matrix: \n",
      "TP:  95  FN:  2  FP:  1  TN:  45\n"
     ]
    }
   ],
   "source": [
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "TN=0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    # count TP,FP,FN,FP\n",
    "    if y_test[i]==0:\n",
    "        if y_predict[i]<0.5: \n",
    "            TN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "    else:\n",
    "        if y_predict[i]>=0.5:\n",
    "            TP+=1\n",
    "        else:\n",
    "            FN+=1\n",
    "        \n",
    "# calculate precision, recall and f1\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1: \",f1)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(\"TP: \",TP,\" FN: \",FN,\" FP: \",FP,\" TN: \",TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
